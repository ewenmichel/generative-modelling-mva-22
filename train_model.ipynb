{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ewenmichel/miniconda3/envs/altegrad/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 11.72it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 11.70it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 11.63it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 11.71it/s]\n",
      "loss: 0.2617:  43%|████▎     | 13007/30000 [00:57<14:57:12,  3.17s/it] /Users/ewenmichel/miniconda3/envs/altegrad/lib/python3.10/site-packages/ema_pytorch/ema_pytorch.py:165: UserWarning: The operator 'aten::lerp.Scalar_out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343686130/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  ma_params.data.lerp_(current_params.data, 1. - current_decay)\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:12<00:00,  8.10it/s] \n",
      "sampling loop time step: 100%|██████████| 100/100 [00:12<00:00,  7.76it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:12<00:00,  7.82it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:12<00:00,  7.87it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 12.24it/s] \n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 12.25it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [16:30<00:00,  9.91s/it]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 12.30it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 12.05it/s]  \n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 12.04it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 12.04it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 12.07it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 11.39it/s]  \n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 11.70it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 11.73it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 11.74it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 11.71it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 11.71it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 11.71it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 11.71it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 12.00it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 12.01it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 12.01it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:08<00:00, 12.01it/s]\n",
      "loss: 0.3173:  65%|██████▌   | 19637/30000 [44:01:13<9:49:03,  3.41s/it] "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from bit_diffusion import Unet, Trainer, BitDiffusion\n",
    "\n",
    "model = Unet(\n",
    "    dim = 32,\n",
    "    channels = 3,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    ")\n",
    "\n",
    "bit_diffusion = BitDiffusion(\n",
    "    model,\n",
    "    image_size = 128,\n",
    "    timesteps = 100,\n",
    "    time_difference = 0.1,       # they found in the paper that at lower number of timesteps, a time difference during sampling of greater than 0 helps FID. as timesteps increases, this time difference can be set to 0 as it does not help\n",
    "    use_ddim = True              # use ddim\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    bit_diffusion,\n",
    "    'data/train/',             # path to your folder of images\n",
    "    results_folder = './results',     # where to save results\n",
    "    num_samples = 16,                 # number of samples\n",
    "    train_batch_size = 4,             # training batch size\n",
    "    gradient_accumulate_every = 4,    # gradient accumulation\n",
    "    train_lr = 1e-4,                  # learning rate\n",
    "    save_and_sample_every = 1000,     # how often to save and sample\n",
    "    train_num_steps = 30000,         # total training steps\n",
    "    ema_decay = 0.995,                # exponential moving average decay\n",
    ")\n",
    "\n",
    "trainer.load(\"13\")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b361c001a35e4df5d61a1c2d55742e80469c144a59b264207a8ccea62793ab6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('altegrad')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
